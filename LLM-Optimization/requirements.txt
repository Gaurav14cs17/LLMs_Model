# LLM Optimization Course - Requirements
# ========================================

# Core ML Frameworks
torch>=2.0.0
torchvision>=0.15.0
transformers>=4.35.0
accelerate>=0.24.0
datasets>=2.14.0

# Quantization
bitsandbytes>=0.41.0
auto-gptq>=0.5.0
autoawq>=0.1.6
optimum>=1.14.0

# PEFT (Parameter-Efficient Fine-Tuning)
peft>=0.6.0

# Pruning & Sparsity
torch-pruning>=1.2.0

# Export & Deployment
onnx>=1.14.0
onnxruntime>=1.16.0
onnxruntime-gpu>=1.16.0

# Efficient Inference
flash-attn>=2.3.0
xformers>=0.0.22
triton>=2.1.0

# Utilities
numpy>=1.24.0
scipy>=1.11.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
pandas>=2.0.0
tqdm>=4.65.0

# Jupyter Support
jupyter>=1.0.0
ipywidgets>=8.0.0
notebook>=7.0.0

# Evaluation
evaluate>=0.4.0
rouge-score>=0.1.2
nltk>=3.8.0

# Monitoring
tensorboard>=2.14.0
wandb>=0.15.0

# Code Quality
black>=23.0.0
isort>=5.12.0
pylint>=3.0.0

